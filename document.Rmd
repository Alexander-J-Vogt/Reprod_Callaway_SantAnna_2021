---
title: "Difference-in-Differece with Various Treatment Timing and Multiple Period"
output: html_notebook
---

# 1. Difference-in-Difference with Multiple Time Periods

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

$$
Y_{g, t}=\alpha_t+\alpha_g+\sum_{e=-K}^{-2} \delta_e^{\text {anticip }} \cdot D_{g, t}^e+\sum_{e=0}^L \beta_e \cdot D_{g, t}^e+v_{g, t}
$$

# 4. Code

```{r}
# In this line Remove existing environment in order to make sure that 
rm(list = ls(all = TRUE))

# set seed for replication
set.seed(1234)

# libraries
library(tidyverse)
library(data.table)
library(haven)
library(DRDID)
library(did)
library(BMisc)
library(plm)
library(lmtest)

# Please set here the working directory

# load data
qwi <- read_rds(paste0("./", "01_Data/cs_data.RDS"))
qwi <- data.table(qwi)
  
```

## 4.1 Calculating the aggregated average treatment effects

In the following the two-step procedure of CS (2021) is implemented in form of two functions separate functions. In the first function `calculating_agg_att`, the partially and overall aggregated average treatment effects (Agg. ATE) are calculated by first calculating the group-time average treatment effects $$ATT(g,t)$$ and than using the aggregation methodology of CS (2021). The second function `calculate_att_se`, calculates the standard error of each aggregated average treatment effects with the multiplier bootstrap.

The function `calculating_agg_att` is the main function of this term paper and needs several arguments in order to calculate Agg. ATT. The structure of the function is inspired by the did-package of CS (2021). The core argument is the method-argument, where the user can choose between the simple-weighted ATE,group-specific ATE, calendar time effect, and event-study effects with balanced and unbalanced event time. In order to calculate the event study effect the function needs to know for how long a period should have been treated, which can be specified with the balanced-argument. Moreover, the argument unconditional_ind decides on whether to use the unconditional parallel trend assumption (PTA) or the conditional PTA, which is the default option. If the conditional PTA is used, pre-treatment covariates should be given to the argument formula. Additionally, this function needs a balanced panel data set and the name of time indicator variable, the group-indicator variable, the outcome variable, the individual identification variable and the treatment-indicator variable.

```{r}

# Unconditional DiD-estimator  -----

# Unconditional_att is the function to calculate the unconditional ATT in the 
# calculating_agg_att is calculated by simply taking the difference of the 
# treatment effects of the pre- and post-treatment assuming that the standard 
# PTA holds.
unconditional_att <- function(outcome_post, outcome_pre, treatment) {
  results_post <- lm(outcome_post ~ treatment)
  results_pre  <- lm(outcome_pre ~ treatment)
  coef_post <- coef(results_post)[2]
  coef_pre  <- coef(results_pre)[2]
  att <- coef_post - coef_pre
  
  # Saving the results in list
  results <- list()
  results <- list(ATT = att)
}

spec_formula_log <- ~ -1 + lwhite_pop + lpoverty + lpop_1000s + lmedian_income_1000s + leduc

calculating_agg_att <- function(data,
                                year_input,
                                group_input,
                                outcome_input,
                                id_input,
                                treatment,
                                formula,
                                unconditional_ind = FALSE,
                                method,
                                balanced = NULL
                                ) {
  
  # 1. Standardize variables & basic calculations
  # In this section, the arguments given to the function are re-defined in order
  # to allow a universal usage of the function and the basic variables needed for 
  # the further procedure are defined 
  
  # The variables are re-defined and standardized in order to guarantee universal
  # application of the function.
  data_original <- data
  data_original <- data_original |>
    rename(year    = !!sym(year_input),
           group   = !!sym(group_input),
           outcome = !!sym(outcome_input),
           id      = !!sym(id_input)
           )
  unconditional <- unconditional_ind
  covariate_formula <- formula
  
  # data_original <- data_original |>
  #   rename(year    = date_y, #!!sym(year_input),
  #          group   = group, #!!sym(group_input),
  #          outcome = lnEmp, #!!sym(outcome_input),
  #          id      = county_id# !!sym(id_input)
  #   )
  #   unconditional <- FALSE
  #   covariate_formula <- ~ -1 + lwhite_pop + lpoverty + lpop_1000s + lmedian_income_1000s + leduc
  # Determining the unique time periods, groups and the number of unique values 
  # of the id-variable . Thereby, the timelist is a tx1 vector and grouplist 
  # a gx1 vector.
  timelist <- unique(data_original$year)
  grouplist <- sort(unique(data_original$group))
  grouplist <- grouplist[grouplist != 0]
  n_unique <- length(unique(data_original$id))
  
  # Here, a empty data frame is setup for later saving the ATT(g,t) 
  num_of_cases <- (length(timelist) - 1) * length(grouplist)
  attgt.df <- as.data.frame(matrix(NA, nrow = num_of_cases, ncol = 3))
  colnames(attgt.df) <- c("attgt", "group", "year")
  att.gt.ls <- list()
  
  # The number-variable is needed for the Loop, which calculates the different
  # ATT(g,t) and is needed for saving the ATT(g,t) in the right row of the
  # data frame.
  number <- 1
  
  # 2. The double loop calculates the ATT(g,t), i.e., the disaggregated ATE.
  # Therefore, the first loop iterates over all different groups and the inner 
  # loop iterates over the available periods. Thus, the inner loop calculates 
  # all the ATT(g,t) of one group.
  for (g in grouplist) {
     for (t in timelist) {
      
      # The data needs to be assigned for every iteration newly, in order to have 
      # the full dataset available as later in the code, the data gets subset.
      data <- data_original
      
      # The ATT(g,t) is always calculated for two periods and excludes any 
      # information of periods before, after and in the middle of the two periods.
      # By excluding the other periods, it is possible to estimate the ATT(g,t)
      # without the influence of dynamic heterogeneous effects of the period before.
      # Therefore,(A) a pre-treatment period (or reference year) needs to be determinant
      # and (B) the data needs to include two years and only a control and treatment
      # group.
      
      # (A) The choice of reference year depends on whether the period of the current 
      # loop is laying in the pre- or post-treatment period. If the current period
      # of the loop is laying in the post-treatment period, the if-condition sets
      # the reference year equal to the first pre-treatment period of a group. Thus,
      # the treatment effects is calculated. Otherwise, the reference year is set
      # equal to the current period of the loop iteration and a pseudo- ATT(g,t)
      # is calculated, which allows to test the PTA.
      if (t >= g) {
        reference_year <- g - 1
      } else {
        reference_year <- t
      }
      
      # (B) After having determined the reference year, the dataset can be subsetted
      # given the reference year and the period if the current period of the loop
      # iteration + 1. Therefore, the data includes only two time periods.
      data <- subset(data, year %in% c(reference_year, t + 1)) 
      
      # In the next step, the two-year data sets gets further restricted by only
      # including the "never-treated" group and the treatment group of the 
      # current loop iteration. Therefore, a index-indicator is need in order to
      # get a dataset, which only includes the necessary groups.
      data$g_ <- ifelse(data$group == g, 1, 0) 
      data$c_ <- ifelse(data$group == 0, 1, 0)
      index_gc <- (data$g_ == 1) | (data$c_ == 1)
      data_sel <- data[index_gc,] # can be deleted

      # # Create treatment indicator and date variables as character # Can be deleted
      data_sel <- data_sel|>
         mutate(treat = ifelse(group == g, 1, 0))
      
      # This if-condition makes sure that the subsetted dataset includes exactely 
      # two periods and jumps into the next loop if this is not the case.
      if (length(unique(data$year)) == 2) {
      
      # The function, which calculate the conditional and unconditional ATT(g,t),
      # need data in the wide format such that there exists a outcome variable
      # for the pre- and post-treatment period. Thus, rows of the wide dataset 
      # is equal to the number of unique observations. (The code follows
      # the idea of BMisc::panel2cs2, but is a own implementation.)
      data_wide       <- arrange(data_sel, id, year)
      data_wide$.y1   <- data_wide$outcome
      data_wide$.y0   <- shift(data_wide$outcome, 1)
      data_wide$index <- ifelse(data_wide$year == reference_year, 1, 0)  
      data_wide       <- data_wide[data_wide$index == 0,]
      
      } else {
        next
      }

      # The final step is to actually compute the conditional and unconditional ATT(g,t)
      # for group at period t. Thereby, the user of the function can simply choose
      # between these two option by simply setting the argument "unconditional"
      # respectively to the preferred estimator.
      
      # Creating a matrix with all values of the pre-treatment covariates
      covariates <- model.matrix(covariate_formula, data_wide)
      
      if (unconditional == TRUE) {
      # The first option is to calculate the ATT(g,t) with the PTA holding unconditionally.
      # The estimation has already been  explained in detail in the beginning of this
      # section and is a classical canonical DiD linear regression.
      att <- unconditional_att(outcome_post = data_wide$.y1,
                               outcome_pre  = data_wide$.y0,
                               treatment    = data_wide$treat)
        
      } else {
      
      # The second option is to calculate the ATT(g,t) with the PTA holding conditional
      # to pre-treatment covariates. Thereby, the non-parametric identified doubly-robust
      # estimator is used, which combines the outcome regression estimator (OR) of 
      # Heckman et al. (1997) and inverse probability weighting estimator (IPW) of 
      # Abadie (2005). The OR relies on a correctly modeled outcome evolution of 
      # the control group conditional on covariates, while the IPW only relies on 
      # the correctly modeled probability of belonging to group g (CS, 2021). 
      # The doubly-robust estimators is a combination of both of the OR and IPW
      # and thus has the advantage that it yields a correct estimator, if either
      # the ouctome evolution or the probabilites of belonging to a group is
      # correctly estimated.
      att <- DRDID::drdid_panel(y1 = data_wide$.y1,
                                y0 = data_wide$.y0,
                                D  = data_wide$treat,
                                covariates = covariates,
                                inffunc    = FALSE,
                                boot       = FALSE)
      }
      
      # The ATT(g,t) effects are saved in this data frame.
      attgt.df[number, 1] <- att$ATT 
      attgt.df[number, 2] <- g
      attgt.df[number, 3] <- t + 1
      
      # Number is increased after every iteration by one in order to save the 
      # values of the next iteration in the next row of the data frame.
      number <- number + 1
    }
  }
  

# 4. Aggregated ATT(g,t) -------------------------------------------------------

## 4.0 Preparation of probabilities & vectors ----------------------------------
  
  # Set up a copy of the original dataset as the original dataset is later needed
  # for the event study effects.
  data <- data_original
  
  # After having calculated the ATT(g,t) for each group in each period,
  # the Agg. ATT can be calculated. Therefore, the weights for aggregating the 
  # the different ATT(g,t) needs to be calculated and a post index is calculated,
  # which gives gives the row of each ATT(g,t) for each group in the post-treatment
  # period.
  
  # time_min <- min(data$year)
  # time_max <- max(data$year)
  
  # The following loop, the probability of belonging to a treated group g are
  # are calculated. Therefore, a empty dataset is prepared for saving the 
  # weights in it.
  weights <- as.data.frame(matrix(NA, nrow = length(grouplist), ncol = 3))
  colnames(weights) <- c("group", "size", "probs")
  
  for (i in seq_along(grouplist)) {
    # First, the group for which the weight is calculated, is getting selected.
    g <- grouplist[i]
    
    # Then, the size of the subgroup g is calculated and divided by the total
    # size of the unique observations in the panel dataset.
    weights[i, 1] <- g
    weights[i, 2] <- nrow(data[data$group == g & data$year == g, ])
    weights[i, 3] <- weights[i, 2] / n_unique
  }
  
  # In the last step, the probabilities of each group are getting merged 
  # with the data frame, which contains the ATT(g,t). This dataset is playing 
  # a key role in the following section for calculation of the Agg ATT. 
  attgt_probs_df <- merge(attgt.df, weights, by.x = "group" ) 
  
  # The index_post variable is a index for the Prob-ATT-df, which  gives the row of each ATT(g,t)
  # for each group in the post-treatment period.
  index_post   <- which(attgt_probs_df$year >= attgt_probs_df$group)
  

## 4.1 Simple Weighted Average of ATT(g,t) -------------------------------------
  
  if (method == "simple_att") {
  
    # The simple-weighted average of ATT(g,t) is a measure to evaluate the overall 
    # ATE of the treatment and might be a good first step to evaluate the treatment 
    # before continuing with less aggregated ATE. In order to calculate the measure,
    # all the ATT(g,t) of all groups in the post-treatment period are weighted 
    # with the respective probability of belonging to the group g. Then  all these 
    # weighted ATT(g,t) are summed up and divided by kappa. Kappa has the purpose
    # to normalize the weights and is the sum of all used probabilities over all 
    # time periods and groups. E.g., group 2006 contributes two ATT(g,t) to the 
    # simple-weighted ATT, if the sample goes until 2007. Thus, the weight of group
    # 2006 enters kappa two times.
    
    # This line selects the relevant ATT(g,t) in the post-treatment period.
    aggte_simple <- attgt_probs_df[index_post, ]
    
    # Than the  sum of probabilities corresponding to ATT(g,t) in the
    # post-treatment period over all groups is calculated.
    kappa <- sum(aggte_simple$probs)
    
    # The simple-weighted ATT is calculated according to the above description.
    simple_att_est <- round(sum(aggte_simple$attgt * aggte_simple$probs) / kappa, 4)
    
    # This line saves the results.
    results <- list(overall_att = simple_att_est)
    return(results)
  }


## 4.2 Group-Time ATT(g,t) -----------------------------------------------------
  
  if (method == "group_specific_att") {
    
    # The group-specific ATE is of relevance for researchers if they want to 
    # evaluate the heterogeneity of a policy with respect to treatment timing.
    # Thereby, the group-specific ATE is calculated by taking the mean of all 
    # available ATT(g,t) of a group g (Sant'Anna, 2022).
    
    # The first step is to select the ATT(g,t) of each group in the post-treatment 
    # period from the data frame with all ATT(g,t) and the corresponding weights
    # of each group.
    gte_df <- attgt_probs_df[index_post, ]
    
    # An empty data frame is created, in which the group-specific ATE are saved.
    gte_results <- data.frame(matrix(NA, nrow = length(grouplist), ncol = 2))
    colnames(gte_results) <- c("time", "coef")
    
    # Than, the second step is to calculate the group-specific ATE by taking the 
    # mean of all ATT(g,t) of a group g as above described. In each loop iteration,
    # the group-specific ATE is calculated for another group. Therefore, the 
    # grouplist variable is used, which contains all unique treatment groups.
    for (i in seq_along(grouplist)) {
      g <- grouplist[i]
      gte_results[i, "time"] <- g
      gte_results[i, "coef" ]  <- round(mean(gte_df[gte_df$group == g, "attgt"]), 4)
    }
    
    # The calculation of the overall ATE of the group-specific ATE follows the
    # the same strategy of simple weighted average of ATT. Thus, the sum of
    # weighted group-specific ATT is taken, while the weights are the
    # probability of belonging to group g. Than, this sum is divided by the sum of
    # of all group weights for normalization purposes.
    agg_gte_results <- round(sum(gte_results$coef * weights$probs) / sum(weights$probs), 4)
    
    # This line saves the results.
    results <- list(partial_att = gte_results, overall_att = agg_gte_results)
    return(results)
  } # End of group-specific effects if-clause

  
## 4.3 Calendar Time Effects ---------------------------------------------------
  if (method == "calendar_att") {
    
    # Calendar time effects are interesting if the question arises on how large the 
    # average treatment effects after a certain number of periods is (CS, 2021). 
    # For example, researchers could be interested in the effects of policy several 
    # years after its first introduction. 
    # The calendar time effects are calculated by taking the sum of ATT(g,t) with 
    # the corresponding weights by calendar time, e.g., by year t. The first year 
    # for which the calendar time effect is calculated, is the year in which a
    # treated group is treated the first time.
    
    # In order to calculate the calendar time effects for each year, the loop for 
    # calculating the effects needs iterate over all calendar times. 
    
    # Than, an empty data frame is created, in which the calendar time effects are 
    # going to be save.
    # group_min <- min(grouplist)
    aggte_ct <- attgt_probs_df[index_post,] # If mistake change back to org code attgt.df$year >= group_min & attgt.df$year >= attgt.df$group,]
    #Therefore, 
    # The variable calendar_timelist is determined with all unique 
    # calendar times, which is needed in order to calculate the calendar time effects
    
    calendar_timelist <- unique(aggte_ct$year)
    
    cte_results <- as.data.frame(matrix(NA, nrow = length(calendar_timelist), ncol = 2))
    colnames(cte_results) <- c("time", "coef")
    # In this loop the calendar effects for each calendar time are calculated.
    for (i in seq_along(calendar_timelist)) {
      # Selecting the post-treatment year for which the calendar time effects 
      # will be calculated in the current iteration.
      calendar_time <- calendar_timelist[i]
      df <- aggte_ct[aggte_ct$year == calendar_time,]
      # Calculating the actual calendar time effects.
      group_prob <- df$probs / sum(df$probs)
      cte_results[i, "time"] <- calendar_time
      cte_results[i, "coef"]   <- round(sum(df$attgt * group_prob), 4)
    }
    
    # The overall calendar time effects is calculated by taking the mean of all
    # calendar time effects. 
    agg_att_ct <- round(mean(cte_results$coef), 4)
    
    # Save final calendar time effects
    results <- list(partial_att = cte_results, overall_att = agg_att_ct)
    return(results)
 } # End of calendar-time effects if-clause


## 4.4 Event Study Design -------------------------
# Preparation of event time data in the case, the event study design is calculated
   if (method %in% c("unbalanced_eventstudy", "balanced_eventstudy")) {
      
    # In this section the event study effects is calculated for the balanced and
    # unbalanced event time. Therefore, the interest lays on the heterogeneity of 
    # treatment effects with respect to exposure to the treatment. In order to be
    # able to calculate to the event study effect, the event time needs to be 
    # calculated by taking the difference between year of the ATT(g,t) and the 
    # group of a ATT(g,t).  
    attgt_et <- attgt_probs_df
    attgt_et$eventtime <- attgt_et$year - attgt_et$group
    
    # Than all pre-treatment event times are exluded as the interest lays on the 
    # exposure to the treatment.
    attgt_et <- attgt_et[attgt_et$eventtime >= 0, ]

### 4.4.1 Event Study Effect ---------------------------------------------------
    if (method == "unbalanced_eventstudy") {
      
      # The event study effects without balancing the event time measures the
      # effect of a treatment e periods after a treatment. Therefore, the weighted
      # sum of all group-time ATT of a event-time e is taken and divided by the 
      # sum of all weights of groups in event-time e. Thus, the logic of this
      # calculation is very similar to the calculation of the calendar time effects.
      
      # The calculation of the event study effect requires a variable, which
      # contains the unique set of event-time. Than, the loop can be used to 
      # calculate the event study effects for each event-time e
      # Creating an empty dataset to safe the event study effects of each
      # event-time e
      eventime_timelist <- unique(attgt_et$eventtime)
      et_results <- as.data.frame(matrix(NA, nrow = length(eventime_timelist), ncol = 2))
      colnames(et_results) <- c("time", "coef")
      
      for (i in seq_along(eventime_timelist)) {
        # Selecting the event-time e of the current iteration
        eventime_time <- eventime_timelist[i]
        df         <- attgt_et[attgt_et$eventtime == eventime_time,]
        # Calculating the event study effect according to the aforementioned 
        # description.
        group_prob <- df$probs / sum(df$probs)
        et_results[i, "time"]   <- eventime_time
        et_results[i, "coef"]   <- round(sum(df$attgt * group_prob), 4)
      }
      
      # Calculate aggregated event study effects
      agg_et <- round(mean(et_results$coef),4)
      
      # The overall event study effect is calculated by taking the mean of all
      # event study effects time effects.
      results <- list(partial_att = et_results, overall_att = agg_et)
      return(results)
    } # End of unbalanced event-study effects if-clause

## 4.4.2 Eventstudy with balanced group ---------------------------------------
    if (method == "balanced_eventstudy" & !is.null(balanced)) {
      
      # The event study effect with groups being balanced with respect to the
      # event-time e condition the event study effect on a group being observed
      # at least for a certain amount of time according to CS (2021). Thereby,
      # the calculation of the "balanced event study effect" is identical to the 
      # "unbalanced event study effect". Thus, this is not explained in detail
      # anymore, but the steps in order to get the "balanced" data.
      
      # First, the indicator on how many periods a group should have been 
      # observed is re-defined as it is an argument, which the user needs to 
      # give the function.
      balance_groups <- balanced
      
      # Secondly, it must be identified, which group experienced the stated
      # amount of period defined by the variable "balance_groups".
      # List of unique event-time.
      
      # Therefore, the number of post-treatment periods is calculated by iterating
      # over the vector with the unique treatment groups.
      grouplist_et <- unique(attgt_et$group)
      att_per_group <- sapply(grouplist_et, function(g){
        # Create a subset of the ATT(g,t) with only group g being represented.
        df <- attgt_et[attgt_et$group == g,]
        # Than sum up the number of post-treatment period
        n  <- nrow(df)
        n
      })
      
      # Create a data frame, which contains the information on the number
      # of post-treatment periods.
      att_per_group <- data.frame(grouplist_et, att_per_group)
      colnames(att_per_group) <- c("eventtime", "abs_nr_att")

      # Than, the if-condition in the loop determines whether a group was 
      # exposed to the treatment for the required length of "balanced_group".
      # In the end, groups_to_exclude contains the groups, which were not observed
      # for required treatment length.
      groups_to_exclude <- c()
      for ( i in seq_along(att_per_group$eventtime) ) {
        if ( att_per_group[i, 2] < balance_groups + 1 ) {
          groups_to_exclude[i] <- att_per_group[i, 1]
        } else {
          next
        }
      }
      
      # In the last step to get the "balanced" data frame with the ATT(g,t). 
      # The groups determined above are excluded.
      groups_to_exclude <- groups_to_exclude[!is.na(groups_to_exclude)]
      attgt_et_bal <- attgt_et[!attgt_et$group %in% groups_to_exclude,]
      
      # Now, the event study effect can be calclated in the same way as the 
      # in the Unbalanced event study effect section.
      eventime_timelist <- unique(attgt_et_bal$eventtime)
      att_et_bal <- as.data.frame(matrix(NA, nrow = length(eventime_timelist), ncol = 2))
      colnames(att_et_bal) <- c("time", "coef")
        
      for (i in seq_along(eventime_timelist)) {
        # Selecting the post-treatment year for which the calendar time effects will be calculated
        eventime_time <- eventime_timelist[i]
        df         <- attgt_et[attgt_et_bal$eventtime == eventime_time,]
        # Calcualte the 
        group_prob <- df$probs / sum(df$probs)
        att_et_bal[i, "time"]   <- eventime_time
        att_et_bal[i, "coef"]   <- round(sum(df$attgt * group_prob), 4)
        }  
      
      # Only event study effects are shown, which lay in the minimum requirement
      # of how long a group must have been observed.
      et_bal_results <- att_et_bal[att_et_bal$time < balance_groups + 1,]
      
      # Calculate the aggregated event study effects by taking the mean of all
      # event study effects in the different event-time.
      agg_bal_et <- round(mean(et_bal_results$coef), 4)
      
      # Save results on balanced event study effects
      results <- list(partial_att = et_bal_results, overall_att = agg_bal_et)
      return(results)
    } # End of balanced event study effects if-clause

  } # End of data-preparation if-clause

} # End of calculating_agg_att
```

The function `calculate_att_se` is the final step of implementing the methodology of CS (2021). The outcome of the function is the partially and overall ATE of the choosen method and the corresponding standard errors, which are calculated by using the multiplier bootstrap proposed in CS (2021). Thereby, it is important to mention that the multiplier bootstrap in CS (2021) is used to bootstrap the influence function of an ATE, while in this term paper it used to calculate a distribution of the partial and ATT from which the distribution is calculated.

```{r}
calculate_att_se <- function(data = qwi,
                             year_input = "date_y",
                             group_input = "group",
                             outcome_input = "lnEmp",
                             id_input = "county_id",
                             treatment = treated,
                             formula = spec_formula,
                             unconditional_ind = FALSE,
                             method = "group_att",
                             balanced = FALSE) {
  
  # These variables are redefined for universal usage in the function. 
  data <- data
  data_for_b <- data |>
    rename(id = !!sym(id_input)) |>
    as.data.frame()
  method <- method
  # The number of iteration is determined here.
  iter <- 10
  b_res_overall <- list()
  b_res_partial <- list()
  # This loop is the implementation of the multiplier bootstrap. The core
  # difference to the standard bootstrapping is that there are us no resembling
  # but only a fraction of the overall total population size is used for
  # calculating the ATE.
  for (i in 1:iter) {
  
    # The selection of the subset of the total sample is determined by the 
    # Bernoulli Variates according to CS (2021), Thereby, a vector with values
    # of the binomial distribution is created. The vector has the same length
    # as the unique observation of the dataset. The probability for which 1 are
    # drawn from is equal to the following term:
    kappa <- ( sqrt(5) + 1 ) / 2
    p <- kappa / sqrt(5)
    n_row <- length(data_for_b$id)
    # Creation of the above mentioned vector.
    bernoulli_variates <- rbinom(n_row, 1, p)
    
    # In these three lines the subset of the total sample is drawn, which is then
    # used to calculate the partial and overall ATE with the method of choice.
    county <- unique(data_for_b$id)
    county <- county[bernoulli_variates == 1]
    b_data <- data_for_b |> filter(id %in% county)
    b_est <- calculating_agg_att(data = b_data,
                                 year_input = year_input,
                                 group_input = group_input,
                                 outcome_input = outcome_input,
                                 id_input = "id",
                                 treatment = treated,
                                 formula = formula,
                                 unconditional_ind = unconditional_ind,
                                 method = method,
                                 balanced = balanced)
    
    # The results of the ATE with only a sub sample are saved here, and these
    # variables contain the distribution of every partial and overall ATE.
    if (method != "simple_att")  b_res_partial[[i]] <- t(as.matrix(b_est$partial_att$coef))
    b_res_overall[[i]] <- round(b_est$overall_att, 4)
  }
  
  # The standard error of the partial and overall ATE are calculated from their 
  # respective distribution of ATE, but before the list of which contains the
  # ATT must be collapsed in order to yield a data frame.
  b_res_partial <- map_dfr(b_res_partial, as.data.frame)
  se_partial <- apply(b_res_partial, 2, sd)
  b_res_overall <- unlist(b_res_overall)
  se_overall <- round(sd(b_res_overall), 4)
  
  # Calculating the ATT with the full sample.
  est <- calculating_agg_att(data = data,
                             year_input = year_input,
                             group_input = group_input,
                             outcome_input = outcome_input,
                             id_input = id_input,
                             treatment = treated,
                             formula = spec_formula,
                             unconditional_ind = unconditional_ind,
                             method = method,
                             balanced = balanced)
  
  # The results of the ATT and the corresponding standard erros are
  # saved as the outcome of this function.
  est$partial_att$b_se <- round(se_partial, 4)
  est$overall_att <- cbind(est$overall_att, se_overall)
  colnames(est$overall_att) <- c("coef", "b_se")
  
  return(est)
}
  
```



```{r}
calculate_various_specifications <-  function(data) {
                
  method_opt <- c("simple_att", "group_specific_att", "calendar_att", 
                  "unbalanced_eventstudy", "balanced_eventstudy")

  for ( m in method_opt ) {
    paste0("Method: ", m)
    assign(paste0("c_est_", m), calculate_att_se(data = data,
                                               year_input = "date_y",
                                               group_input = "group",
                                               outcome_input = "lnEmp",
                                               id_input = "county_id",
                                               treatment = treated,
                                               formula = spec_formula,
                                               unconditional_ind = FALSE,
                                               method = m,
                                               balanced = 1))
    
  }

  for ( m in method_opt ) {
    paste0("Method: ", m)
    assign(paste0("u_est_", m), calculate_att_se(data = data,
                                                    year_input = "date_y",
                                                    group_input = "group",
                                                    outcome_input = "lnEmp",
                                                    id_input = "county_id",
                                                    treatment = treated,
                                                    formula = spec_formula,
                                                    unconditional_ind = TRUE,
                                                    method = m,
                                                    balanced = 1))
    
  }
    
   c_twfe <- plm(lnEmp ~ -1 + post_treat + treated + post_treat * treated + 
                    lwhite_pop + lpoverty + lpop_1000s + lmedian_income_1000s + 
                    leduc, data = data, index = c("county_id", "date_y"), model = "within") 
   
   c_twfe_df <- as.data.frame(matrix(NA, nrow = 1, ncol = 2))
   colnames(c_twfe_df) <- c("coef", "se")
   c_twfe_df[1,1] <- round(coef(c_twfe)[2], 4)
   c_twfe_df[1,2] <- round(lmtest::coeftest(c_twfe, vcov = vcovHC)[2,2], 4)
   
    
   u_twfe <- plm(lnEmp ~ -1 + post_treat + treated + post_treat * treated 
                       , data = data, index = c("county_id", "date_y"), model = "within")
   
   u_twfe_df <- as.data.frame(matrix(NA, nrow = 1, ncol = 2))
   colnames(u_twfe_df) <- c("coef", "se")
   u_twfe_df[1,1] <- round(coef(u_twfe)[2], 4)
   u_twfe_df[1,2] <- round(lmtest::coeftest(u_twfe, vcov = vcovHC)[2,2], 4)

   
   cond <- list(twfe = c_twfe_df, 
                simple = c_est_simple_att, 
                group = c_est_group_specific_att,
                calendar = c_est_calendar_att, 
                eventstudy_bal = c_est_balanced_eventstudy,
                eventstudy_unbal = c_est_unbalanced_eventstudy)
   
   uncond <- list(twfe = c_twfe_df, 
                  simple = u_est_simple_att, 
                  group = u_est_group_specific_att,
                  calendar = u_est_calendar_att, 
                  eventstudy_bal = u_est_balanced_eventstudy,
                  eventstudy_unbal = u_est_unbalanced_eventstudy) 
   
   results <- list(c_results = cond,
                   u_results = uncond)
   
}

## Calculating all methods except balanced eventstudy
calculate_various_specifications_west <-function(data) {
  
  method_opt <- c("simple_att", "group_specific_att", "calendar_att", 
                  "unbalanced_eventstudy")
  
  for ( m in method_opt ) {
    paste0("Method: ", m)
    assign(paste0("c_est_", m), calculate_att_se(data = data,
                                                 year_input = "date_y",
                                                 group_input = "group",
                                                 outcome_input = "lnEmp",
                                                 id_input = "county_id",
                                                 treatment = treated,
                                                 formula = spec_formula,
                                                 unconditional_ind = FALSE,
                                                 method = m,
                                                 balanced = 1))
    
  }
  
  for ( m in method_opt ) {
    paste0("Method: ", m)
    assign(paste0("u_est_", m), calculate_att_se(data = data,
                                                 year_input = "date_y",
                                                 group_input = "group",
                                                 outcome_input = "lnEmp",
                                                 id_input = "county_id",
                                                 treatment = treated,
                                                 formula = spec_formula,
                                                 unconditional_ind = TRUE,
                                                 method = m,
                                                 balanced = 1))
    
  }
  
  c_twfe <- plm(lnEmp ~ -1 + post_treat + treated + post_treat * treated + 
                  lwhite_pop + lpoverty + lpop_1000s + lmedian_income_1000s + 
                  leduc, data = data, index = c("county_id", "date_y"), model = "within") 
  
  c_twfe_df <- as.data.frame(matrix(NA, nrow = 1, ncol = 2))
  colnames(c_twfe_df) <- c("coef", "se")
  c_twfe_df[1,1] <- round(coef(c_twfe)[2], 4)
  c_twfe_df[1,2] <- round(lmtest::coeftest(c_twfe, vcov = vcovHC)[2,2], 4)
  
  
  u_twfe <- plm(lnEmp ~ -1 + post_treat + treated + post_treat * treated 
                , data = data, index = c("county_id", "date_y"), model = "within")
  
  u_twfe_df <- as.data.frame(matrix(NA, nrow = 1, ncol = 2))
  colnames(u_twfe_df) <- c("coef", "se")
  u_twfe_df[1,1] <- round(coef(u_twfe)[2], 4)
  u_twfe_df[1,2] <- round(lmtest::coeftest(u_twfe, vcov = vcovHC)[2,2], 4)
  
  
  cond <- list(twfe = c_twfe_df, 
               simple = c_est_simple_att, 
               group = c_est_group_specific_att,
               calendar = c_est_calendar_att,
               eventstudy_unbal = c_est_unbalanced_eventstudy)
  
  uncond <- list(twfe = c_twfe_df, 
                 simple = u_est_simple_att, 
                 group = u_est_group_specific_att,
                 calendar = u_est_calendar_att,
                 eventstudy_unbal = u_est_unbalanced_eventstudy) 
  
  results <- list(c_results = cond,
                  u_results = uncond)
  
}
```

# 5. Application of Callaway & Sant'Anna (2021)

Callaway & Sant'Anna (2021) show as an example of their methodology for calculating aggregated average treatment effects the   
```{r warning=FALSE, include=FALSE}

# In these lines, the subset of each Census Region is created.
qwi_west <- qwi |> filter(region == "West")
qwi_midwest <- qwi |> filter(region == "Midwest")
qwi_south <- qwi |> filter(region == "South")

# Defining the covariate formula for the ATE holding under conditional ATE
spec_formula <- ~ -1 + lwhite_pop + lpoverty + lpop + lmeduab_income + leduc

# Calc
results_total   <- calculate_various_specifications(qwi)
results_west    <- calculate_various_specifications_west(qwi_west)
results_midwest <- calculate_various_specifications(qwi_midwest)
results_south   <- calculate_various_specifications(qwi_south)
```

```{r echo=FALSE}
print("(1) Full sample: Conditional ATE with Doubly-Robust estimators")
print(results_total$c_results)

```
```{r}
print("(2) Full sample: Unconditional ATE")
print(results_total$u_results)
```


```{r}
print("(3) Western Census Region: Conditional ATE")
print(results_west$c_results)
```

```{r}
print("(4) Western Census Region: Unconditional ATE")
print(results_west$c_results)
```


```{r}
print("(5) Midwest Census Region: Conditional ATE")
print(results_midwest$c_results)
```

```{r}
print("(6) Midwest Census Region: Unconditional ATE")
print(results_midwest$c_results)
```

```{r}
print("(7) Soutern Census Region: Conditional ATE")
print(results_south$c_results)
```

```{r}
print("(8) Southern Census Region: Unconditional ATE")
print(results_$c_results)
```



